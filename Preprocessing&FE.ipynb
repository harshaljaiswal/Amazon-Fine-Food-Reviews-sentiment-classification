{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing essential libraries\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.externals import joblib\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the SQLite Table to read data.\n",
    "con = sqlite3.connect('database.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering only positive and negative reviews i.e. \n",
    "# not taking into consideration those reviews with Score=3\n",
    "filtered_data = pd.read_sql_query(\"\"\" SELECT * FROM Reviews WHERE Score != 3 \"\"\", con) \n",
    "\n",
    "# Give reviews with Score>3 a positive rating, and reviews with a score<3 a negative rating.\n",
    "def partition(x):\n",
    "    if x < 3:\n",
    "        return 'negative'\n",
    "    return 'positive'\n",
    "\n",
    "#changing reviews with score less than 3 to be positive and vice-versa\n",
    "actualScore = filtered_data['Score']\n",
    "positiveNegative = actualScore.map(partition) \n",
    "filtered_data['Score'] = positiveNegative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score values for both positive and negative reviews\n",
    "filtered_data['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting data according to ProductId in ascending order\n",
    "sorted_data=filtered_data.sort_values('ProductId', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
    "\n",
    "# Dealing with Deduplication of entries\n",
    "final=sorted_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\n",
    "final.shape\n",
    "\n",
    "#Checking to see how much % of data still remains\n",
    "(final['Id'].size*1.0)/(filtered_data['Id'].size*1.0)*100\n",
    "\n",
    "final=final[final.HelpfulnessNumerator<=final.HelpfulnessDenominator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking whether anything is NaN or not\n",
    "final.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the dataframe for time based slicing\n",
    "final.sort_values(by =['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking Only 100k sample points with 85197 positive and 14803 negative\n",
    "sample100K_data = final.iloc[:100000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sample100K_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking number of positive and negative points \n",
    "sample100K_data['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample100K_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find sentences containing HTML tags\n",
    "import re\n",
    "i=0;\n",
    "for sent in sample100K_data['Text'].values:\n",
    "    if (len(re.findall('<.*?>', sent))):\n",
    "        print(i)\n",
    "        print(sent)\n",
    "        break;\n",
    "    i += 1;\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop = set(stopwords.words('english')) #set of stopwords\n",
    "sno = nltk.stem.SnowballStemmer('english') #initialising the snowball stemmer\n",
    "\n",
    "def cleanhtml(sentence): #function to clean the word of any html-tags\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', sentence)\n",
    "    return cleantext\n",
    "def cleanpunc(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    return  cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for implementing step-by-step the checks mentioned in the pre-processing phase\n",
    "i=0\n",
    "str1=' '\n",
    "final_string=[]\n",
    "all_positive_words=[] # store words from +ve reviews here\n",
    "all_negative_words=[] # store words from -ve reviews here.\n",
    "s=''\n",
    "for sent in sample100K_data['Text'].values:\n",
    "    filtered_sentence=[]\n",
    "    #print(sent);\n",
    "    sent=cleanhtml(sent) # remove HTMl tags\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):    \n",
    "                if(cleaned_words.lower() not in stop):\n",
    "                    s=(sno.stem(cleaned_words.lower())).encode('utf8')\n",
    "                    filtered_sentence.append(s)\n",
    "                    if (sample100K_data['Score'].values)[i] == 'positive': \n",
    "                        all_positive_words.append(s) #list of all words used to describe positive reviews\n",
    "                    if(sample100K_data['Score'].values)[i] == 'negative':\n",
    "                        all_negative_words.append(s) #list of all words used to describe negative reviews reviews\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue \n",
    "    #print(filtered_sentence)\n",
    "    str1 = b\" \".join(filtered_sentence) #final string of cleaned words\n",
    "    #print(\"***********************************************************************\")\n",
    "    \n",
    "    final_string.append(str1)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample100K_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample100K_data['CleanedText']=final_string #adding a column of CleanedText which displays the data after pre-processing of the review \n",
    "sample100K_data['CleanedText']=sample100K_data['CleanedText'].str.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample100K_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking out the class variable or score into separate series.\n",
    "target = sample100K_data['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving class variable or score into separate file for future use.\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(target, 'target.joblib')\n",
    "joblib.dump(sample100K_data, 'sample100K_data_prepros.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data from previously created class variable or score and preprossed sample 100k data.\n",
    "from sklearn.externals import joblib\n",
    "target = joblib.load('target.joblib')\n",
    "sample100K_data = joblib.load('sample100K_data_prepros.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "X = sample100K_data.iloc[:,:]\n",
    "y = target\n",
    "\n",
    "# split the data set into train and test\n",
    "X_1, X_test, y_1, y_test = model_selection.train_test_split(X, y, test_size=0.3, random_state=0,stratify = y)\n",
    "\n",
    "# split the train data set into cross validation train and cross validation test\n",
    "X_tr, X_cv, y_tr, y_cv = model_selection.train_test_split(X_1, y_1, test_size=0.3, random_state=1, stratify = y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving class variable or score into separate file for future use.\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(y_tr, 'y_tr.joblib')\n",
    "joblib.dump(y_cv, 'y_cv.joblib')\n",
    "joblib.dump(y_test, 'y_test.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words (BoW) implementation for Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating BoW model. Taking max_features = 2000 as obtained from literature.\n",
    "count_vect = CountVectorizer(max_features = 2000, min_df=50)\n",
    "x_train_BOW = count_vect.fit_transform(X_tr['CleanedText'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_CV_BOW = count_vect.transform(X_cv['CleanedText'].values)\n",
    "x_test_BOW = count_vect.transform(X_test['CleanedText'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving BoW matrix for future use.\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(x_train_BOW, 'x_train_BOW.joblib')\n",
    "joblib.dump(x_CV_BOW, 'x_CV_BOW.joblib')\n",
    "joblib.dump(x_test_BOW, 'x_test_BOW.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF implementation for Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a tf_idf vector. Taking max_features = 2000 and min_df=50 as obtained from literature.\n",
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2),max_features = 2000, min_df=50)\n",
    "x_train_TFIDF = tf_idf_vect.fit_transform(X_tr['CleanedText'].values)\n",
    "x_CV_TFIDF = tf_idf_vect.transform(X_cv['CleanedText'].values)\n",
    "x_test_TFIDF = tf_idf_vect.transform(X_test['CleanedText'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving TF-IDF matrix for future use.\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(x_train_TFIDF, 'x_train_TFIDF.joblib')\n",
    "joblib.dump(x_CV_TFIDF, 'x_CV_TFIDF.joblib')\n",
    "joblib.dump(x_test_TFIDF, 'x_test_TFIDF.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train your own Word2Vec model using your own text corpus\n",
    "# For train data\n",
    "i=0\n",
    "list_of_TRsent=[]\n",
    "for sent in X_tr['CleanedText'].values:\n",
    "    list_of_TRsent.append(sent.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_count = 5 considers only words that occured atleast 5 times\n",
    "w2v_model=Word2Vec(list_of_TRsent,min_count=5,size=50, workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avg W2V implementation for Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For CV data\n",
    "list_of_CVsent=[]\n",
    "for sent in X_cv['CleanedText'].values:\n",
    "    list_of_CVsent.append(sent.split())\n",
    "    \n",
    "# For test data\n",
    "list_of_TSsent=[]\n",
    "for sent in X_test['CleanedText'].values:\n",
    "    list_of_TSsent.append(sent.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average Word2Vec\n",
    "# compute average word2vec for each review.\n",
    "w2v_words = list(w2v_model.wv.vocab)\n",
    "def Avg_W2V(list_of_sent):   \n",
    "    sent_vectors = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "    for sent in list_of_sent: # for each review/sentence\n",
    "        sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "        cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "        for word in sent: # for each word in a review/sentence\n",
    "            if word in w2v_words:\n",
    "                vec = w2v_model.wv[word]\n",
    "                sent_vec += vec\n",
    "                cnt_words += 1\n",
    "        if cnt_words != 0:\n",
    "            sent_vec /= cnt_words\n",
    "        sent_vectors.append(sent_vec)\n",
    "    return(sent_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train_AVG_W2V = Avg_W2V(list_of_TRsent)\n",
    "x_CV_AVG_W2V = Avg_W2V(list_of_CVsent)\n",
    "x_test_AVG_W2V = Avg_W2V(list_of_TSsent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_AVG_W2V = pd.DataFrame(x_train_AVG_W2V)\n",
    "x_CV_AVG_W2V = pd.DataFrame(x_CV_AVG_W2V)\n",
    "x_test_AVG_W2V = pd.DataFrame(x_test_AVG_W2V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x_test_AVG_W2V.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving Avg W2V matrix for future use.\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(x_train_AVG_W2V, 'x_train_AVG_W2V.joblib')\n",
    "joblib.dump(x_CV_AVG_W2V, 'x_CV_AVG_W2V.joblib')\n",
    "joblib.dump(x_test_AVG_W2V, 'x_test_AVG_W2V.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
